#### 主题模型
---
##### 1. 词向量
1）word2vec 原理、推导.

word2vec 是一种基于神经网络的分布表示方法。与分布表示相对的是符号表示。分布表示还可以通过矩阵分解来计算，比如SVD等，主题模型也可以计算词的压缩表示。word2vec 是对神经概率语言模型等的改进，

2）hierarchical softmax 与 negative sampling.

noise contrastive estimatio（NCE，噪声对比估计）是一种对观测数据的概率密度进行估计的方法，通过构造一些分布已知的 noise data，将概率密度的估计问题转化为一个 logistic regression 问题.

3）word2vec 与 TFIDF 比较；与 LDA 比较.

4）word2vec 怎么进行增量式训练.

gensim 可以进行增量式训练，C 版本的好像不行，但都无法改变词表的大小.

5）word2vec 目标函数？为什么没加正则.

6）word2vec 考虑词语的顺序？

7）CBOW 和 skip-gram 对比？为什么 skip-gram + negative sampling 效果好？

8）TextRank 原理


参考资料

1）来斯惟博士论文：基于神经网络的词和文档语义向量表示方法研究.

2）来斯惟博客

3）[word2vec 中的数学原理详解](http://blog.csdn.net/itplus/article/details/37969519)

4）[noise contrastive estimation 文献](https://yinwenpeng.wordpress.com/2013/09/25/noise-contrastive-estimation/)

5）[噪声对比估计加速词向量训练](http://models.paddlepaddle.org/2017/04/21/nce-cost-README.html)

6）[TFIDF 概率解释](http://www.cnblogs.com/weidagang2046/archive/2012/10/22/tf-idf-from-probabilistic-view.html)


##### 2 随机采样方法

参考资料：

1）[从随机过程到马尔可夫链蒙特卡罗方法](http://www.cnblogs.com/daniel-D/p/3388724.html)

---
#### 算法竞赛
利用用户周围的各种类型数据来判断用户是否会按期还款，是一个二分类问题，采用 AUC 评测.

##### 数据预处理
1. 缺失值

1）缺失量少，均值，中位数等填充；

2）缺失量多，离散化；

3）拟合模型填充.

2. 异常值

1）基于统计的方法：3 sigma

2）聚类方法

3）isolation forest 等算法.

##### 特征工程
1）连续特征；

2）离散特征；

3）特征组合；

##### 特征选择与特征降维
1）特征选择

过滤式、包裹式、嵌入式

2）特征降维

##### 模型
LR、RF、GBDT、XGBoost

1）为什么 LR 需要归一化或者取对数；为什么 LR 把特征离散化后效果更好？

参考：[连续特征的离散化：在什么情况下将连续的特征离散化之后可以获得更好的效果？](https://www.zhihu.com/question/31989952)

2）RF 和 GBDT 的区别

3）GBDT 和 XGBoost 的区别

参考：
1）[陈天奇：XGBoost 与 Boosted Tree](http://www.52cs.org/?p=429)

2）[机器学习算法中 GBDT 和 XGBoost 的区别有哪些](https://www.zhihu.com/question/41354392/answer/128008021?group_id=773629156532445184)

##### 模型组合
平均、bagging、stacking

##### 评测指标
AUC：AUC 的定义和本质，有哪些计算方法.
